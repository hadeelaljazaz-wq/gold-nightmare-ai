"""
Al Kabous AI - Advanced Image Processing with OCR
Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØµÙˆØ± Ù…Ø¹ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„Ø´Ø§Ø±Øª
"""

import cv2
import numpy as np
import pytesseract
import easyocr
from PIL import Image, ImageEnhance, ImageFilter
import base64
import io
import re
import logging
import requests
import json
from typing import Dict, List, Any, Optional, Tuple
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

class ChartImageProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ø±ØªØ§Øª"""
    
    def __init__(self):
        # Initialize EasyOCR reader
        try:
            self.ocr_reader = easyocr.Reader(['en', 'ar'], gpu=False)
            logger.info("âœ… EasyOCR initialized successfully")
        except Exception as e:
            logger.warning(f"âš ï¸ EasyOCR initialization failed: {e}")
            self.ocr_reader = None
        
        # Price extraction patterns
        self.price_patterns = [
            r'\b\d{1,5}(?:\.\d{1,5})\b',  # 2451.23, 1234.5
            r'\b\d{1,5}(?:,\d{3})*(?:\.\d{1,5})?\b',  # 2,451.23
            r'\$\s*\d{1,5}(?:,\d{3})*(?:\.\d{1,5})?\b',  # $2,451.23
            r'XAU[:/]\s*\d{1,5}(?:\.\d{1,5})\b',  # XAU: 2451.23
            r'GOLD[:/]\s*\d{1,5}(?:\.\d{1,5})\b',  # GOLD: 2451.23
        ]
        
        self.timeframe_patterns = [
            r'\b(?:M|H|D|W|MN)\d*\b',  # M1, M5, H1, H4, D1, W1, MN1
            r'\b\d+\s*(?:min|hour|day|week|month)s?\b',  # 1 hour, 15 min
            r'\b(?:1|5|15|30)m\b',  # 1m, 5m, 15m, 30m
            r'\b(?:1|4|12|24)h\b',  # 1h, 4h, 12h, 24h
        ]
        
        # Currency pair patterns
        self.pair_patterns = [
            r'\b(?:XAU|GOLD)/USD\b',
            r'\b(?:EUR|GBP|USD|JPY|AUD|CAD|CHF|NZD)/(?:USD|EUR|JPY|GBP)\b',
            r'\bGOLD\b',
            r'\bXAUUSD\b',
        ]

    def optimize_chart_image(self, image_data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """
        ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ - ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        """
        try:
            # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©
            img = Image.open(io.BytesIO(image_data))
            
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ RGB Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            optimization_log = {
                "original_size": img.size,
                "steps_applied": []
            }
            
            # 1. Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„Ø¯Ù‚Ø© (ÙƒÙ…Ø§ Ø§Ù‚ØªØ±Ø­Øª)
            target_width, target_height = 1920, 1080
            if img.size[0] < target_width or img.size[1] < target_height:
                img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                optimization_log["steps_applied"].append("Resolution upscaling to 1920x1080")
            
            # 2. ØªØ­Ø³ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenCV
            img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            
            # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯Ø© ÙˆØ§Ù„ÙˆØ¶ÙˆØ­
            sharpening_kernel = np.array([[-1,-1,-1], 
                                        [-1, 9,-1], 
                                        [-1,-1,-1]])
            img_cv = cv2.filter2D(img_cv, -1, sharpening_kernel)
            optimization_log["steps_applied"].append("Sharpening filter applied")
            
            # 3. ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLAHE
            lab = cv2.cvtColor(img_cv, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            img_cv = cv2.merge([l,a,b])
            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_LAB2BGR)
            optimization_log["steps_applied"].append("CLAHE contrast enhancement")
            
            # 4. ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­ÙˆØ§Ù
            img_cv = cv2.bilateralFilter(img_cv, 9, 75, 75)
            optimization_log["steps_applied"].append("Bilateral noise reduction")
            
            # 5. ØªØ­Ø³ÙŠÙ† Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„Ù†ØµÙˆØµ
            gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ù„Ù„Ù†ØµÙˆØµ
            clahe_text = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(4,4))
            gray = clahe_text.apply(gray)
            
            # ØªØ­ÙˆÙŠÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ù„Ø£Ù„ÙˆØ§Ù†
            img_cv = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
            optimization_log["steps_applied"].append("Text clarity enhancement")
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PIL
            img_optimized = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
            
            # Ø­ÙØ¸ ÙƒÙ€ bytes Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©
            output_buffer = io.BytesIO()
            img_optimized.save(output_buffer, format='PNG', optimize=True, quality=95)
            optimized_data = output_buffer.getvalue()
            
            optimization_log["final_size"] = img_optimized.size
            optimization_log["size_improvement"] = f"{len(optimized_data) / len(image_data):.2f}x"
            
            logger.info(f"âœ… Image optimized: {len(optimization_log['steps_applied'])} enhancements applied")
            
            return optimized_data, optimization_log
            
        except Exception as e:
            logger.error(f"âŒ Image optimization failed: {e}")
            return image_data, {"error": str(e)}

    def extract_text_from_chart_advanced(self, image_data: bytes) -> Dict[str, Any]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†ØµÙˆØµ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª OCR
        """
        try:
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ø£ÙˆÙ„Ø§Ù‹
            optimized_data, optimization_log = self.optimize_chart_image(image_data)
            
            # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
            img = Image.open(io.BytesIO(optimized_data))
            
            text_data = {
                "prices": [],
                "timestamps": [],
                "full_text": "",
                "confidence_scores": [],
                "optimization_applied": optimization_log,
                "extraction_methods": []
            }
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: EasyOCR Ø§Ù„Ù…Ø­Ø³Ù†
            if self.ocr_reader:
                try:
                    # ØªØ­Ø³ÙŠÙ† Ø¥Ø¶Ø§ÙÙŠ Ù„Ù€ EasyOCR
                    img_for_easy = self._prepare_for_easyocr(img)
                    easy_results = self.ocr_reader.readtext(np.array(img_for_easy), detail=1)
                    
                    for (bbox, text, confidence) in easy_results:
                        if confidence > 0.6:  # Ø¹ØªØ¨Ø© Ø«Ù‚Ø© Ø£Ø¹Ù„Ù‰
                            text_data["full_text"] += text + " "
                            text_data["confidence_scores"].append(confidence)
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
                            prices = re.findall(r'\b\d{1,5}(?:\.\d{1,5})?\b', text)
                            for price_str in prices:
                                try:
                                    price = float(price_str)
                                    if 1000 <= price <= 5000:
                                        text_data["prices"].append(price)
                                except ValueError:
                                    continue
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª
                            times = re.findall(r'\d{1,2}:\d{2}', text)
                            text_data["timestamps"].extend(times)
                    
                    text_data["extraction_methods"].append("EasyOCR_Advanced")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Advanced EasyOCR failed: {e}")
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Tesseract Ø§Ù„Ù…Ø­Ø³Ù†
            try:
                # ØªØ­Ø³ÙŠÙ† Ø®Ø§Øµ Ù„Ù€ Tesseract
                img_for_tess = self._prepare_for_tesseract(img)
                cv_img = cv2.cvtColor(np.array(img_for_tess), cv2.COLOR_RGB2BGR)
                
                # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù€ Tesseract
                configs = [
                    '--oem 3 --psm 6',  # Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø§Ù…Ø©
                    '--oem 3 --psm 8',  # Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØ±Ø¯Ø©
                    '--oem 3 --psm 13',  # Ù„Ù„Ù†ØµÙˆØµ ÙÙŠ Ø®Ø· ÙˆØ§Ø­Ø¯
                    '--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789.,:$'  # Ù„Ù„Ø£Ø±Ù‚Ø§Ù… ÙÙ‚Ø·
                ]
                
                for config in configs:
                    try:
                        tessearct_text = pytesseract.image_to_string(cv_img, config=config)
                        if tessearct_text.strip():
                            text_data["full_text"] += " " + tessearct_text
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† Tesseract
                            prices = re.findall(r'\b\d{1,5}(?:\.\d{1,5})?\b', tessearct_text)
                            for price_str in prices:
                                try:
                                    price = float(price_str)
                                    if 1000 <= price <= 5000:
                                        text_data["prices"].append(price)
                                except ValueError:
                                    continue
                    
                    except Exception as e:
                        continue
                
                text_data["extraction_methods"].append("Tesseract_Multi_Config")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Advanced Tesseract failed: {e}")
            
            # ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            text_data["prices"] = list(set(text_data["prices"]))  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª
            text_data["timestamps"] = list(set(text_data["timestamps"]))
            text_data["full_text"] = text_data["full_text"].strip()
            text_data["average_confidence"] = np.mean(text_data["confidence_scores"]) if text_data["confidence_scores"] else 0.0
            
            logger.info(f"âœ… Advanced text extraction: {len(text_data['prices'])} prices, {len(text_data['timestamps'])} timestamps")
            
            return text_data
            
        except Exception as e:
            logger.error(f"âŒ Advanced text extraction failed: {e}")
            return {"error": str(e)}

    def _prepare_for_easyocr(self, image: Image.Image) -> Image.Image:
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ EasyOCR Ø¨Ø´ÙƒÙ„ Ù…Ø­Ø³Ù†"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ Ù„Ù„Ù†ØµÙˆØµ
            gray_img = image.convert('L')
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ù„Ù„Ù†ØµÙˆØµ
            enhancer = ImageEnhance.Contrast(gray_img)
            enhanced = enhancer.enhance(2.0)
            
            # ØªØ­ÙˆÙŠÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ù„Ø£Ù„ÙˆØ§Ù† (EasyOCR ÙŠÙØ¶Ù„ RGB)
            rgb_img = enhanced.convert('RGB')
            
            return rgb_img
            
        except Exception as e:
            logger.error(f"âŒ EasyOCR preparation failed: {e}")
            return image

    def _prepare_for_tesseract(self, image: Image.Image) -> Image.Image:
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ Tesseract Ø¨Ø´ÙƒÙ„ Ù…Ø­Ø³Ù†"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ OpenCV
            cv_img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)
            
            # ØªØ·Ø¨ÙŠÙ‚ threshold Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Øµ Ø£Ø³ÙˆØ¯ Ø¹Ù„Ù‰ Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡
            _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            kernel = np.ones((1,1), np.uint8)
            thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
            
            # ØªØ­ÙˆÙŠÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ù€ PIL
            result_img = Image.fromarray(thresh).convert('RGB')
            
            return result_img
            
        except Exception as e:
            logger.error(f"âŒ Tesseract preparation failed: {e}")
            return image

    def chart_to_data_context(self, image_data: bytes, user_context: Optional[str] = None) -> str:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø´Ø§Ø±Øª Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ø³Ù‚Ø© Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚
        """
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            text_data = self.extract_text_from_chart_advanced(image_data)
            
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø§Ù…Ù„
            context_parts = []
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø§Ø±Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            context_parts.append("=== ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø´Ø§Ø±Øª ===")
            
            # Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
            if text_data.get("prices"):
                prices = sorted(text_data["prices"])
                context_parts.append(f"Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {prices}")
                context_parts.append(f"Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø± Ù…Ø±Ø¦ÙŠ: ${max(prices):.2f}")
                context_parts.append(f"Ø£Ø¯Ù†Ù‰ Ø³Ø¹Ø± Ù…Ø±Ø¦ÙŠ: ${min(prices):.2f}")
                context_parts.append(f"Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±: ${max(prices) - min(prices):.2f}")
            
            # Ø§Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
            if text_data.get("timestamps"):
                context_parts.append(f"Ø§Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {text_data['timestamps']}")
            
            # Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
            if text_data.get("full_text"):
                context_parts.append(f"Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {text_data['full_text'][:200]}...")
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø«Ù‚Ø©
            if text_data.get("average_confidence"):
                context_parts.append(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {text_data['average_confidence']:.2f}")
            
            # Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù… Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if user_context:
                context_parts.append(f"Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù… Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_context}")
            
            # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
            context_parts.extend([
                "",
                "=== ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ ===",
                "1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø£Ø¹Ù„Ø§Ù‡ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø©",
                "2. Ø§Ø±Ø¨Ø· Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø¨Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø±Ø¦ÙŠØ© ÙÙŠ Ø§Ù„Ø´Ø§Ø±Øª",
                "3. Ø­Ù„Ù„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„Ø¨ØµØ±ÙŠØ©",
                "4. Ù‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ù…Ø­Ø¯Ø¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„",
                "5. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø©ØŒ Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ"
            ])
            
            formatted_context = "\n".join(context_parts)
            
            logger.info("âœ… Chart context built successfully")
            return formatted_context
            
        except Exception as e:
            logger.error(f"âŒ Chart context building failed: {e}")
            return f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø§Ø±Øª: {str(e)}"

    def get_ohlc_data_simulation(self, symbol: str = 'XAUUSD', timeframe: str = '4h') -> Dict[str, Any]:
        """
        Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª OHLC Ù„Ù„Ø´Ø§Ø±Øª (ÙŠÙ…ÙƒÙ† Ø±Ø¨Ø·Ù‡Ø§ Ø¨Ù€ APIs Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ø§Ø­Ù‚Ø§Ù‹)
        """
        try:
            # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù…Ø­Ø§ÙƒÙŠØ© (ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… API)
            sample_data = [
                {"time": "2024-01-30 08:00", "open": 2650.45, "high": 2658.30, "low": 2648.20, "close": 2655.80},
                {"time": "2024-01-30 12:00", "open": 2655.80, "high": 2662.15, "low": 2652.40, "close": 2659.70},
                {"time": "2024-01-30 16:00", "open": 2659.70, "high": 2665.90, "low": 2657.30, "close": 2661.25},
                {"time": "2024-01-30 20:00", "open": 2661.25, "high": 2668.45, "low": 2659.80, "close": 2665.15},
                {"time": "2024-01-31 00:00", "open": 2665.15, "high": 2670.30, "low": 2663.70, "close": 2668.90},
            ]
            
            # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            formatted_data = f"Ø¨ÙŠØ§Ù†Ø§Øª {symbol} - Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ {timeframe}:\n"
            formatted_data += "Ø§Ù„ÙˆÙ‚Øª | ÙØªØ­ | Ø£Ø¹Ù„Ù‰ | Ø£Ø¯Ù†Ù‰ | Ø¥ØºÙ„Ø§Ù‚\n"
            formatted_data += "-" * 50 + "\n"
            
            for candle in sample_data:
                formatted_data += f"{candle['time']} | {candle['open']:.2f} | {candle['high']:.2f} | {candle['low']:.2f} | {candle['close']:.2f}\n"
            
            # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            prices = [candle['close'] for candle in sample_data]
            stats = {
                "current_price": prices[-1],
                "highest": max([candle['high'] for candle in sample_data]),
                "lowest": min([candle['low'] for candle in sample_data]),
                "average": sum(prices) / len(prices),
                "volatility": max(prices) - min(prices)
            }
            
            formatted_data += f"\nØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª:\n"
            formatted_data += f"Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ: ${stats['current_price']:.2f}\n"
            formatted_data += f"Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø±: ${stats['highest']:.2f}\n"
            formatted_data += f"Ø£Ø¯Ù†Ù‰ Ø³Ø¹Ø±: ${stats['lowest']:.2f}\n"
            formatted_data += f"Ø§Ù„Ù…ØªÙˆØ³Ø·: ${stats['average']:.2f}\n"
            formatted_data += f"Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª: ${stats['volatility']:.2f}\n"
            
            return {
                "raw_data": sample_data,
                "formatted_text": formatted_data,
                "statistics": stats,
                "symbol": symbol,
                "timeframe": timeframe
            }
            
        except Exception as e:
            logger.error(f"âŒ OHLC data simulation failed: {e}")
            return {"error": str(e)}

    def analyze_chart_intelligently(self, image_data: bytes, user_context: Optional[str] = None) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ø´Ø§Ù…Ù„ Ù„Ù„Ø´Ø§Ø±Øª - Ø§Ù„Ù†Ù‡Ø¬ Ø§Ù„Ù…Ø®ØªÙ„Ø· Ø§Ù„Ù…Ù‚ØªØ±Ø­
        """
        try:
            analysis_result = {
                "optimization_log": {},
                "text_extraction": {},
                "ohlc_simulation": {},
                "comprehensive_prompt": "",
                "optimized_image_data": None,
                "confidence_score": 0.0
            }
            
            logger.info("ğŸ” Starting intelligent chart analysis...")
            
            # 1. ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
            optimized_data, optimization_log = self.optimize_chart_image(image_data)
            analysis_result["optimization_log"] = optimization_log
            analysis_result["optimized_image_data"] = optimized_data
            
            # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            text_data = self.extract_text_from_chart_advanced(optimized_data)
            analysis_result["text_extraction"] = text_data
            
            # 3. Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª OHLC
            ohlc_data = self.get_ohlc_data_simulation()
            analysis_result["ohlc_simulation"] = ohlc_data
            
            # 4. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø§Ù…Ù„
            chart_context = self.chart_to_data_context(optimized_data, user_context)
            
            # 5. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ Prompt Ø§Ù„Ø´Ø§Ù…Ù„
            comprehensive_prompt = f"""
ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ØªÙ‚Ø¯Ù… Ù„Ø´Ø§Ø±Øª Ø§Ù„Ø°Ù‡Ø¨ - Ù†Ù‡Ø¬ Ù…Ø®ØªÙ„Ø· Ø°ÙƒÙŠ

=== Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© ===
{chart_context}

=== Ø¨ÙŠØ§Ù†Ø§Øª OHLC Ø§Ù„Ù…Ø­Ø§ÙƒÙŠØ© ===
{ohlc_data.get('formatted_text', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')}

=== ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ø¨Ù‚Ø© ===
Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©: {', '.join(optimization_log.get('steps_applied', []))}
Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ: {text_data.get('average_confidence', 0):.2f}

=== Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ ===
{user_context or 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ Ù…Ù‚Ø¯Ù… Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…'}

=== Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ===
Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:
1. Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø©
2. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø£Ø¹Ù„Ø§Ù‡  
3. Ø¨ÙŠØ§Ù†Ø§Øª OHLC Ø§Ù„Ù…Ø­Ø§ÙƒÙŠØ©
4. Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…

Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙÙ†ÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙŠØªØ¶Ù…Ù†:
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…
- Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
- ØªÙˆÙ‚Ø¹Ø§Øª Ù‚ØµÙŠØ±Ø© ÙˆÙ…ØªÙˆØ³Ø·Ø© Ø§Ù„Ù…Ø¯Ù‰
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
- ØªÙˆØµÙŠØ§Øª ØªØ¯Ø§ÙˆÙ„ Ù…Ø­Ø¯Ø¯Ø© Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨

Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚Ø©ØŒ Ø§Ø¹ØªÙ…Ø¯ Ø¨Ø´ÙƒÙ„ Ø£ÙƒØ¨Ø± Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©.
            """.strip()
            
            analysis_result["comprehensive_prompt"] = comprehensive_prompt
            
            # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            confidence_factors = []
            
            if optimization_log.get("steps_applied"):
                confidence_factors.append(0.2)  # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
            
            if text_data.get("prices"):
                confidence_factors.append(0.3)  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
            
            if text_data.get("average_confidence", 0) > 0.7:
                confidence_factors.append(0.2)  # Ø¬ÙˆØ¯Ø© OCR
            
            if ohlc_data.get("raw_data"):
                confidence_factors.append(0.3)  # Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            
            analysis_result["confidence_score"] = sum(confidence_factors)
            
            logger.info(f"âœ… Intelligent analysis complete. Confidence: {analysis_result['confidence_score']:.2f}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ Intelligent chart analysis failed: {e}")
            return {"error": str(e)}

    async def process_chart_image(self, image_data: bytes) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„ØµÙˆØ±Ø© Ø§Ù„Ø´Ø§Ø±Øª Ù…Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØµÙˆØ±Ø© PIL
            image = Image.open(io.BytesIO(image_data))
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
            with ThreadPoolExecutor(max_workers=4) as executor:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ
                texts_task = executor.submit(self._extract_texts, image)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø´Ù…ÙˆØ¹
                colors_task = executor.submit(self._analyze_chart_colors, image)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø±
                prices_task = executor.submit(self._extract_prices_advanced, image)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨ØµØ±ÙŠØ©
                patterns_task = executor.submit(self._detect_chart_patterns, image)
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                texts_info = texts_task.result()
                colors_info = colors_task.result()
                prices_info = prices_task.result()
                patterns_info = patterns_task.result()
            
            # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            analysis_result = {
                "image_info": {
                    "width": image.width,
                    "height": image.height,
                    "format": image.format,
                    "mode": image.mode
                },
                "text_extraction": texts_info,
                "price_analysis": prices_info,
                "visual_analysis": {
                    "colors": colors_info,
                    "patterns": patterns_info
                },
                "trading_context": self._build_trading_context(texts_info, prices_info, colors_info)
            }
            
            logger.info("âœ… Chart image processed successfully")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ Error processing chart image: {e}")
            return {"error": str(e)}

    def _extract_texts(self, image: Image.Image) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR Ù…ØªØ¹Ø¯Ø¯"""
        try:
            texts_info = {
                "all_texts": [],
                "prices": [],
                "timeframes": [],
                "currency_pairs": [],
                "indicators": []
            }
            
            # ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ OCR
            enhanced_image = self._enhance_for_ocr(image)
            
            # EasyOCR extraction
            if self.ocr_reader:
                try:
                    easy_results = self.ocr_reader.readtext(np.array(enhanced_image))
                    for result in easy_results:
                        text = result[1].strip()
                        confidence = result[2]
                        
                        if confidence > 0.5:  # Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©
                            texts_info["all_texts"].append({
                                "text": text,
                                "confidence": confidence,
                                "method": "easyocr"
                            })
                            
                            # ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
                            self._classify_text(text, texts_info)
                            
                except Exception as e:
                    logger.warning(f"âš ï¸ EasyOCR failed: {e}")
            
            # Tesseract OCR as backup
            try:
                # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ OpenCV
                cv_image = cv2.cvtColor(np.array(enhanced_image), cv2.COLOR_RGB2BGR)
                tessearct_text = pytesseract.image_to_string(cv_image, config='--oem 3 --psm 6')
                
                for line in tessearct_text.split('\n'):
                    line = line.strip()
                    if line and len(line) > 2:
                        texts_info["all_texts"].append({
                            "text": line,
                            "confidence": 0.8,  # Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù€ Tesseract
                            "method": "tesseract"
                        })
                        self._classify_text(line, texts_info)
                        
            except Exception as e:
                logger.warning(f"âš ï¸ Tesseract failed: {e}")
            
            return texts_info
            
        except Exception as e:
            logger.error(f"âŒ Text extraction failed: {e}")
            return {"error": str(e)}

    def _enhance_for_ocr(self, image: Image.Image) -> Image.Image:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ OCR Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ RGB
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # ØªÙƒØ¨ÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
            width, height = image.size
            image = image.resize((width * 2, height * 2), Image.LANCZOS)
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ø³Ø·ÙˆØ¹
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.5)
            
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(1.1)
            
            # Ø´Ø­Ø° Ø§Ù„ØµÙˆØ±Ø©
            image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=150, threshold=3))
            
            return image
            
        except Exception as e:
            logger.error(f"âŒ Image enhancement failed: {e}")
            return image

    def _classify_text(self, text: str, texts_info: Dict[str, Any]):
        """ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©"""
        text_upper = text.upper()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
        for pattern in self.price_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù‚Ù…
                clean_price = re.sub(r'[^\d.]', '', match)
                try:
                    price_value = float(clean_price)
                    if 1000 <= price_value <= 5000:  # Ù†Ø·Ø§Ù‚ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…Ø¹Ù‚ÙˆÙ„
                        texts_info["prices"].append({
                            "value": price_value,
                            "original": match,
                            "context": text
                        })
                except ValueError:
                    continue
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        for pattern in self.timeframe_patterns:
            matches = re.findall(pattern, text_upper)
            for match in matches:
                texts_info["timeframes"].append({
                    "timeframe": match,
                    "context": text
                })
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø¹Ù…Ù„Ø§Øª
        for pattern in self.pair_patterns:
            matches = re.findall(pattern, text_upper)
            for match in matches:
                texts_info["currency_pairs"].append({
                    "pair": match,
                    "context": text
                })
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
        indicators = ['RSI', 'MACD', 'MA', 'EMA', 'SMA', 'BB', 'STOCH', 'ADX', 'CCI']
        for indicator in indicators:
            if indicator in text_upper:
                texts_info["indicators"].append({
                    "indicator": indicator,
                    "context": text
                })

    def _extract_prices_advanced(self, image: Image.Image) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† Ø§Ù„Ø´Ø§Ø±Øª"""
        try:
            prices_info = {
                "detected_prices": [],
                "current_price_estimate": None,
                "high_low_estimates": {},
                "axis_analysis": {}
            }
            
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ OpenCV
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ø£Ø³Ø¹Ø§Ø± (Ø¹Ø§Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø£ÙŠÙ…Ù†)
            height, width = gray.shape
            
            # Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø£ÙŠÙ…Ù† (Ø¢Ø®Ø± 15% Ù…Ù† Ø§Ù„Ø¹Ø±Ø¶)
            right_axis = gray[:, int(width * 0.85):]
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ÙˆØ± Ù„Ù€ OCR
            right_axis = cv2.bilateralFilter(right_axis, 9, 75, 75)
            _, right_axis = cv2.threshold(right_axis, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„Ù…Ø­ÙˆØ±
            axis_text = pytesseract.image_to_string(right_axis, config='--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789.,')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙÙŠ Ù†Øµ Ø§Ù„Ù…Ø­ÙˆØ±
            for line in axis_text.split('\n'):
                line = line.strip()
                if line:
                    # ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
                    clean_line = re.sub(r'[^\d.]', '', line)
                    try:
                        if clean_line:
                            price = float(clean_line)
                            if 1000 <= price <= 5000:  # Ù†Ø·Ø§Ù‚ Ø§Ù„Ø°Ù‡Ø¨
                                prices_info["detected_prices"].append(price)
                    except ValueError:
                        continue
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…ÙƒØªØ´ÙØ©
            if prices_info["detected_prices"]:
                prices = sorted(prices_info["detected_prices"])
                prices_info["high_low_estimates"] = {
                    "highest": max(prices),
                    "lowest": min(prices),
                    "range": max(prices) - min(prices)
                }
                # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ (Ù‚Ø¯ ÙŠÙƒÙˆÙ† ÙÙŠ Ø§Ù„Ù…Ù†ØªØµÙ)
                prices_info["current_price_estimate"] = prices[len(prices) // 2]
            
            return prices_info
            
        except Exception as e:
            logger.error(f"âŒ Advanced price extraction failed: {e}")
            return {"error": str(e)}

    def _analyze_chart_colors(self, image: Image.Image) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø´Ø§Ø±Øª Ù„ÙÙ‡Ù… Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚"""
        try:
            colors_info = {
                "dominant_colors": [],
                "candlestick_analysis": {},
                "trend_indicators": {}
            }
            
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ numpy array
            img_array = np.array(image)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø³Ø§Ø¦Ø¯Ø©
            pixels = img_array.reshape(-1, 3)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡ ÙˆØ§Ù„Ø­Ù…Ø±Ø§Ø¡ (ØµØ¹ÙˆØ¯/Ù‡Ø¨ÙˆØ·)
            green_pixels = np.sum((pixels[:, 1] > pixels[:, 0]) & (pixels[:, 1] > pixels[:, 2]))
            red_pixels = np.sum((pixels[:, 0] > pixels[:, 1]) & (pixels[:, 0] > pixels[:, 2]))
            
            total_pixels = len(pixels)
            
            colors_info["candlestick_analysis"] = {
                "green_percentage": (green_pixels / total_pixels) * 100,
                "red_percentage": (red_pixels / total_pixels) * 100,
                "trend_indication": "bullish" if green_pixels > red_pixels else "bearish"
            }
            
            return colors_info
            
        except Exception as e:
            logger.error(f"âŒ Color analysis failed: {e}")
            return {"error": str(e)}

    def _detect_chart_patterns(self, image: Image.Image) -> Dict[str, Any]:
        """ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙÙ†ÙŠØ© ÙÙŠ Ø§Ù„Ø´Ø§Ø±Øª"""
        try:
            patterns_info = {
                "detected_patterns": [],
                "support_resistance": [],
                "trend_lines": []
            }
            
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ OpenCV
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            
            # ÙƒØ´Ù Ø§Ù„Ø®Ø·ÙˆØ· (Ø®Ø·ÙˆØ· Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©)
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)
            
            if lines is not None:
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø·ÙˆØ·
                horizontal_lines = 0
                ascending_lines = 0
                descending_lines = 0
                
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠÙ„
                    if x2 != x1:
                        slope = abs((y2 - y1) / (x2 - x1))
                        if slope < 0.1:  # Ø®Ø· Ø£ÙÙ‚ÙŠ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹
                            horizontal_lines += 1
                        elif (y2 - y1) / (x2 - x1) > 0.1:  # Ø®Ø· ØµØ§Ø¹Ø¯
                            ascending_lines += 1
                        elif (y2 - y1) / (x2 - x1) < -0.1:  # Ø®Ø· Ù‡Ø§Ø¨Ø·
                            descending_lines += 1
                
                patterns_info["trend_lines"] = {
                    "horizontal": horizontal_lines,
                    "ascending": ascending_lines,
                    "descending": descending_lines,
                    "trend_direction": self._determine_trend(ascending_lines, descending_lines)
                }
            
            return patterns_info
            
        except Exception as e:
            logger.error(f"âŒ Pattern detection failed: {e}")
            return {"error": str(e)}

    def _determine_trend(self, ascending: int, descending: int) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ±Ù†Ø¯"""
        if ascending > descending * 1.5:
            return "ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
        elif ascending > descending:
            return "ØµØ§Ø¹Ø¯"
        elif descending > ascending * 1.5:
            return "Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ"
        elif descending > ascending:
            return "Ù‡Ø§Ø¨Ø·"
        else:
            return "Ø¬Ø§Ù†Ø¨ÙŠ"

    def _build_trading_context(self, texts_info: Dict, prices_info: Dict, colors_info: Dict) -> Dict[str, Any]:
        """Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©"""
        try:
            context = {
                "extracted_data_summary": "",
                "confidence_score": 0.0,
                "trading_signals": []
            }
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            summary_parts = []
            confidence_factors = []
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
            if prices_info.get("detected_prices"):
                prices = prices_info["detected_prices"]
                summary_parts.append(f"Ø£Ø³Ø¹Ø§Ø± Ù…ÙƒØªØ´ÙØ©: {len(prices)} Ø³Ø¹Ø±")
                if prices_info.get("current_price_estimate"):
                    summary_parts.append(f"Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ù‚Ø¯Ø±: ${prices_info['current_price_estimate']:.2f}")
                confidence_factors.append(0.3)
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†ØµÙˆØµ
            if texts_info.get("currency_pairs"):
                pairs = [pair["pair"] for pair in texts_info["currency_pairs"]]
                summary_parts.append(f"Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø¹Ù…Ù„Ø§Øª: {', '.join(set(pairs))}")
                confidence_factors.append(0.2)
            
            if texts_info.get("timeframes"):
                timeframes = [tf["timeframe"] for tf in texts_info["timeframes"]]
                summary_parts.append(f"Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©: {', '.join(set(timeframes))}")
                confidence_factors.append(0.1)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
            if colors_info.get("candlestick_analysis"):
                trend = colors_info["candlestick_analysis"]["trend_indication"]
                summary_parts.append(f"Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ù„ÙˆØ§Ù†: {trend}")
                confidence_factors.append(0.2)
            
            # Ø­Ø³Ø§Ø¨ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø«Ù‚Ø©
            context["confidence_score"] = sum(confidence_factors)
            context["extracted_data_summary"] = ". ".join(summary_parts)
            
            # Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„
            if colors_info.get("candlestick_analysis", {}).get("green_percentage", 0) > 60:
                context["trading_signals"].append("Ø¥Ø´Ø§Ø±Ø© ØµØ¹ÙˆØ¯ Ù‚ÙˆÙŠØ© Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†")
            elif colors_info.get("candlestick_analysis", {}).get("red_percentage", 0) > 60:
                context["trading_signals"].append("Ø¥Ø´Ø§Ø±Ø© Ù‡Ø¨ÙˆØ· Ù‚ÙˆÙŠØ© Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†")
            
            return context
            
        except Exception as e:
            logger.error(f"âŒ Context building failed: {e}")
            return {"error": str(e)}


# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ø´ØªØ±Ùƒ
chart_processor = ChartImageProcessor()